{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171a637b-5d11-4bc8-a9b4-4311d36513a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script 3: Hyperparameter Optimization\n",
    "# ==============================================================================\n",
    "# --- User Configuration ---\n",
    "# ==============================================================================\n",
    "# Please modify all tunable parameters in this section.\n",
    "\n",
    "# --- 1. Data Source and Splitting Settings ---\n",
    "# Specify the path to your Excel file\n",
    "EXCEL_FILE_PATH = 'Gap-final dataset.xlsx' # For target1\n",
    "# EXCEL_FILE_PATH = 'Barrier-final dataset.xlsx' # For target2\n",
    "\n",
    "# Define how to slice features (X) and the target (Y) from the data using column index positions.\n",
    "# slice(start, stop) -> 'start' is the beginning index (inclusive), 'stop' is the ending index (exclusive).\n",
    "X_COLS_SLICE = slice(1, -1)  # Example: X is from the 2nd column to the second-to-last column.\n",
    "Y_COLS_SLICE = -1            # Example: Y is the last column.\n",
    "\n",
    "# --- 2. Cross-Validation Settings ---\n",
    "CV_N_SPLITS = 10\n",
    "CV_SHUFFLE = True\n",
    "CV_RANDOM_STATE = 100\n",
    "\n",
    "# --- 3. Bayesian Optimization Settings ---\n",
    "N_ITER_BAYESIAN = 50\n",
    "\n",
    "# --- 4. General Model Settings ---\n",
    "DEFAULT_MODEL_RANDOM_STATE = 0\n",
    "\n",
    "# --- 5. Model Selection ---\n",
    "# Select the models to run here.\n",
    "# 【Uncomment】 a line to 【enable】 a model.\n",
    "# 【Comment out】 a line to 【disable】 a model.\n",
    "ENABLED_MODELS = [\n",
    "    'XGBR',   # XGBoost\n",
    "    'RF',     # Random Forest\n",
    "    'GBRT',   # Gradient Boosting Regressor\n",
    "    'HGBR',   # Hist Gradient Boosting\n",
    "    'ETR',    # Extra Trees Regressor\n",
    "    'CBR',    # CatBoost\n",
    "    'LGBM',   # LightGBM\n",
    "]\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- Model Hyperparameter Search Space Definitions ---\n",
    "# ==============================================================================\n",
    "# This section defines the hyperparameter optimization range for each model.\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "parameter_XGBR = {\n",
    "    'n_estimators': Integer(10, 3000), 'learning_rate': Real(0.01, 0.8, prior='log-uniform'),\n",
    "    'max_depth': Integer(2, 30), 'subsample': Real(0.2, 1.0, prior='uniform'),\n",
    "    'colsample_bytree': Real(0.2, 1.0, prior='uniform'), 'gamma': Real(0, 0.5, prior='uniform'),\n",
    "    'reg_alpha': Real(1e-3, 1.0, prior='log-uniform'), 'reg_lambda': Real(0.1, 10.0, prior='log-uniform')\n",
    "}\n",
    "parameter_RF = {\n",
    "    'n_estimators': Integer(10, 3000), 'max_depth': Integer(2, 30),\n",
    "    'max_features': Categorical(['sqrt', 'log2']), 'min_samples_leaf': Integer(1, 20),\n",
    "    'min_samples_split': Integer(2, 20)\n",
    "}\n",
    "parameter_CBR = {\n",
    "    'iterations': Integer(10, 3000), 'learning_rate': Real(0.01, 0.8, prior='log-uniform'),\n",
    "    'depth': Integer(1, 16), 'l2_leaf_reg': Real(1, 10, prior='log-uniform'),\n",
    "    'subsample': Real(0.2, 1.0, prior='uniform'), 'rsm': Real(0.2, 1.0, prior='uniform')\n",
    "}\n",
    "parameter_LGBM = {\n",
    "    'n_estimators': Integer(10, 3000), 'learning_rate': Real(0.01, 0.8, prior='log-uniform'),\n",
    "    'max_depth': Integer(2, 50), 'num_leaves': Integer(5, 100),\n",
    "    'subsample': Real(0.2, 1.0, prior='uniform'), 'colsample_bytree': Real(0.2, 1.0, prior='uniform'),\n",
    "    'reg_alpha': Real(1e-3, 1.0, prior='log-uniform'), 'reg_lambda': Real(1e-3, 1.0, prior='log-uniform')\n",
    "}\n",
    "parameter_GBRT = {\n",
    "    'n_estimators': Integer(10, 2000), 'learning_rate': Real(0.01, 0.6, prior='log-uniform'),\n",
    "    'max_depth': Integer(2, 20), 'max_features': Categorical(['sqrt', 'log2']),\n",
    "    'min_samples_split': Integer(2, 20), 'min_samples_leaf': Integer(1, 20),\n",
    "    'subsample': Real(0.2, 1.0, prior='uniform')\n",
    "}\n",
    "parameter_HGBR = {\n",
    "    'learning_rate': Real(0.01, 0.8, prior='log-uniform'), 'max_iter': Integer(10, 3000),\n",
    "    'max_depth': Integer(2, 20), 'min_samples_leaf': Integer(1, 20),\n",
    "    'l2_regularization': Real(1e-6, 10.0, prior='log-uniform')\n",
    "}\n",
    "parameter_ETR = {\n",
    "    'n_estimators': Integer(10, 3000), 'max_depth': Integer(2, 30),\n",
    "    'min_samples_split': Integer(2, 20), 'min_samples_leaf': Integer(1, 20),\n",
    "    'max_features': Categorical(['sqrt', 'log2', 1.0])\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# --- Main Script Body (Usually no modification is needed below) ---\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1. Library Imports and Environment Check ---\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import re\n",
    "import xgboost as XGB\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "print(\"--- Script Start ---\")\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostRegressor\n",
    "    catboost_available = True\n",
    "except ImportError:\n",
    "    catboost_available = False\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "    lightgbm_available = True\n",
    "except ImportError:\n",
    "    lightgbm_available = False\n",
    "print(\"Library imports and environment check complete.\")\n",
    "\n",
    "\n",
    "# --- 2. Data Loading and Preprocessing ---\n",
    "X, Y = pd.DataFrame(), pd.Series()\n",
    "try:\n",
    "    print(f\"\\nLoading data from Excel file: {EXCEL_FILE_PATH}\")\n",
    "    df = pd.read_excel(EXCEL_FILE_PATH)\n",
    "    print(\"File loaded successfully.\")\n",
    "\n",
    "    min_cols_required = 2\n",
    "    if isinstance(X_COLS_SLICE, slice):\n",
    "        min_cols_required = max(min_cols_required, abs(X_COLS_SLICE.start or 0), abs(X_COLS_SLICE.stop or 0))\n",
    "    if df.shape[1] < min_cols_required:\n",
    "         raise ValueError(f\"Error: The number of columns in the data is insufficient for slicing with X_COLS_SLICE={X_COLS_SLICE}.\")\n",
    "\n",
    "    X = df.iloc[:, X_COLS_SLICE]\n",
    "    Y = df.iloc[:, Y_COLS_SLICE]\n",
    "    print(f\"Data slicing complete. X shape={X.shape}, Y shape={Y.shape} (Target column: '{Y.name}')\")\n",
    "\n",
    "    print(\"\\nCleaning feature names in X for XGBoost compatibility...\")\n",
    "    X.columns = [re.sub(r'\\[|\\]|<', '_', col) for col in X.columns]\n",
    "    print(\"Column names cleaned.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n!!! Fatal Error: File not found at '{EXCEL_FILE_PATH}'. Please check the path in the configuration section.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"\\n!!! Fatal Error: An error occurred while loading or processing data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Model and Cross-Validation Setup ---\n",
    "cross_Valid = KFold(n_splits=CV_N_SPLITS, shuffle=CV_SHUFFLE, random_state=CV_RANDOM_STATE)\n",
    "\n",
    "# Define all possible model instances\n",
    "ALL_POSSIBLE_ESTIMATORS = {\n",
    "    'XGBR': XGB.XGBRegressor(random_state=DEFAULT_MODEL_RANDOM_STATE, objective='reg:squarederror'),\n",
    "    'RF': RandomForestRegressor(random_state=DEFAULT_MODEL_RANDOM_STATE),\n",
    "    'GBRT': GradientBoostingRegressor(random_state=DEFAULT_MODEL_RANDOM_STATE),\n",
    "    'HGBR': HistGradientBoostingRegressor(random_state=DEFAULT_MODEL_RANDOM_STATE),\n",
    "    'ETR': ExtraTreesRegressor(random_state=DEFAULT_MODEL_RANDOM_STATE)\n",
    "}\n",
    "if catboost_available:\n",
    "    ALL_POSSIBLE_ESTIMATORS['CBR'] = CatBoostRegressor(verbose=False, random_state=DEFAULT_MODEL_RANDOM_STATE, allow_writing_files=False)\n",
    "else:\n",
    "    print(\"Info: CatBoost is not installed. 'CBR' will be ignored if enabled in the configuration.\")\n",
    "\n",
    "if lightgbm_available:\n",
    "    ALL_POSSIBLE_ESTIMATORS['LGBM'] = LGBMRegressor(random_state=DEFAULT_MODEL_RANDOM_STATE, verbosity=-1, objective='regression')\n",
    "else:\n",
    "    print(\"Info: LightGBM is not installed. 'LGBM' will be ignored if enabled in the configuration.\")\n",
    "\n",
    "# Build the list of models to run based on the user's selection in the configuration\n",
    "estimators_for_bayes = {name: ALL_POSSIBLE_ESTIMATORS[name]\n",
    "                        for name in ENABLED_MODELS\n",
    "                        if name in ALL_POSSIBLE_ESTIMATORS}\n",
    "\n",
    "params_mapping = {\n",
    "    'XGBR': parameter_XGBR, 'RF': parameter_RF, 'GBRT': parameter_GBRT,\n",
    "    'HGBR': parameter_HGBR, 'ETR': parameter_ETR\n",
    "}\n",
    "if catboost_available: params_mapping['CBR'] = parameter_CBR\n",
    "if lightgbm_available: params_mapping['LGBM'] = parameter_LGBM\n",
    "\n",
    "if not estimators_for_bayes:\n",
    "    print(\"\\n!!! Fatal Error: No models are enabled for tuning. Please check if the ENABLED_MODELS list in the configuration is empty or fully commented out.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\nSetup complete. The following enabled models will be tuned using {cross_Valid.get_n_splits()}-fold cross-validation: {list(estimators_for_bayes.keys())}\")\n",
    "\n",
    "\n",
    "# --- 4. Run Bayesian Optimization ---\n",
    "grid_searches = {}\n",
    "print(f\"\\nStarting BayesSearchCV for each model (n_iter = {N_ITER_BAYESIAN})...\")\n",
    "\n",
    "for name, estimator in estimators_for_bayes.items():\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n--- Tuning {name} ---\")\n",
    "    if name not in params_mapping:\n",
    "        print(f\"Warning: Parameter space for model {name} not found. Skipping.\")\n",
    "        grid_searches[name] = None\n",
    "        continue\n",
    "\n",
    "    bayes_search = BayesSearchCV(\n",
    "        estimator=estimator, search_spaces=params_mapping[name],\n",
    "        n_iter=N_ITER_BAYESIAN, scoring='r2', cv=cross_Valid,\n",
    "        n_jobs=-1, random_state=DEFAULT_MODEL_RANDOM_STATE, verbose=1\n",
    "    )\n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "            bayes_search.fit(X, Y)\n",
    "        duration = time.time() - start_time\n",
    "        grid_searches[name] = bayes_search\n",
    "        print(f\"--- {name} tuning complete ---\")\n",
    "        print(f\"  Best Score (CV R²): {bayes_search.best_score_:.4f}\")\n",
    "        print(f\"  Best Parameters: {dict(bayes_search.best_params_)}\")\n",
    "        print(f\"  Total tuning time: {duration:.2f} seconds\")\n",
    "    except Exception as e:\n",
    "        duration = time.time() - start_time\n",
    "        print(f\"\\n!!! An error occurred while tuning {name}: {e}\")\n",
    "        print(f\"  Time spent on {name} tuning attempt: {duration:.2f} seconds\")\n",
    "        grid_searches[name] = None\n",
    "\n",
    "# ==============================================================================\n",
    "# --- 5. Final Summary of Best Hyperparameters ---\n",
    "# ==============================================================================\n",
    "print(\"\\n\\n==============================================================================\")\n",
    "print(\"--- Summary of All Model Tuning Results ---\")\n",
    "print(\"==============================================================================\")\n",
    "\n",
    "# Create a dictionary to store the best parameters for all models for potential export\n",
    "all_best_params_for_export = {}\n",
    "\n",
    "# Iterate through all completed search tasks\n",
    "for name, search_result in grid_searches.items():\n",
    "    print(f\"\\n--- Model: {name} ---\")\n",
    "    if search_result:\n",
    "        # Extract the best score and parameters\n",
    "        best_score = search_result.best_score_\n",
    "        best_params = dict(search_result.best_params_)\n",
    "        all_best_params_for_export[name] = best_params\n",
    "\n",
    "        print(f\"  Best R² Score (CV): {best_score:.4f}\")\n",
    "        print(\"  Best Hyperparameters:\")\n",
    "        # For better readability, print each parameter on a new line\n",
    "        for param, value in best_params.items():\n",
    "            # Format floats to 6 decimal places\n",
    "            if isinstance(value, float):\n",
    "                print(f\"    - {param}: {value:.6f}\")\n",
    "            else:\n",
    "                print(f\"    - {param}: {value}\")\n",
    "    else:\n",
    "        # If the model tuning failed or was skipped, display an info message\n",
    "        print(\"  Tuning failed or was skipped.\")\n",
    "print(\"\\n--- Script End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9dd6c6-3f53-45dc-a99c-7d676a28b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script 4: Stacking Ensemble & Evaluation\n",
    "# ==============================================================================\n",
    "# --- User Configuration ---\n",
    "# ==============================================================================\n",
    "# Please modify all tunable parameters in this section.\n",
    "\n",
    "# --- 1. Evaluation Process Settings ---\n",
    "# Number of seeds for repeated external cross-validation (how many times to run the full Stacking evaluation).\n",
    "N_SEEDS_FOR_EVALUATION = 2\n",
    "# Number of folds for the external cross-validation (used for generating OOF predictions and evaluating Stacking).\n",
    "N_SPLITS_OUTER_CV = 10\n",
    "# Strength factor for data augmentation (Gaussian noise). Set to 0 to disable.\n",
    "NOISE_SCALE_FACTOR = 0\n",
    "\n",
    "# --- 2. Meta-Learner Tuning Settings ---\n",
    "# Number of iterations for Meta-Learner Bayesian Optimization (only performed on the first run, i.e., seed=0).\n",
    "META_LEARNER_N_ITER_BAYESIAN = 50\n",
    "# Number of 【splits】 for the Meta-Learner's internal cross-validation (e.g., 5).\n",
    "META_LEARNER_N_SPLITS_CV = 10\n",
    "# Number of 【repeats】 for the Meta-Learner's internal cross-validation (e.g., 1).\n",
    "META_LEARNER_N_REPEATS_CV = 3\n",
    "\n",
    "# --- 3. Plotting and Export Settings ---\n",
    "# Number of top features to display in the feature importance bar chart.\n",
    "N_FEATURES_TO_PLOT = 30\n",
    "# Whether to plot the SHAP swarm plot (this can be time-consuming).\n",
    "PLOT_SHAP_SWARM_PLOT = True\n",
    "# Maximum number of samples for the SHAP swarm plot to prevent memory issues. Set to None for no limit.\n",
    "SHAP_SWARM_SAMPLES_LIMIT = 5000\n",
    "\n",
    "# --- 4. Base Learner Selection ---\n",
    "# Select the models to be used as base learners in the Stacking ensemble.\n",
    "# 【Uncomment】 a line to 【enable】 a model.\n",
    "# 【Comment out】 a line to 【disable】 a model.\n",
    "ENABLED_BASE_LEARNERS = [\n",
    "    'XGBR',   # XGBoost\n",
    "    'RF',     # Random Forest\n",
    "    'GBRT',   # Gradient Boosting Regressor\n",
    "    'HGBR',   # Hist Gradient Boosting\n",
    "    'ETR',    # Extra Trees Regressor\n",
    "    'CBR',    # CatBoost\n",
    "    'LGBM',   # LightGBM\n",
    "]\n",
    "\n",
    "# --- 5. General Random State Settings ---\n",
    "# Used for all models and cross-validation to ensure reproducibility.\n",
    "DEFAULT_MODEL_RANDOM_STATE = 0\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- Main Script Body (Usually no modification is needed below) ---\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1. Library Imports and Environment Check ---\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import shap\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "import xgboost as XGB\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.base import clone\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "\n",
    "# Ignore some common warnings to make the output cleaner.\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "print(\"--- Script Start ---\")\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostRegressor\n",
    "    catboost_available = True\n",
    "except ImportError:\n",
    "    catboost_available = False\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "    lightgbm_available = True\n",
    "except ImportError:\n",
    "    lightgbm_available = False\n",
    "print(\"Library imports and environment check complete.\")\n",
    "\n",
    "\n",
    "# --- 2. Core Variable Loading and Preparation ---\n",
    "# Check if variables from the previous script exist; use mock data if not.\n",
    "if 'X' not in locals() and 'X' not in globals():\n",
    "    print(\"Warning: Variable 'X' is not defined. Using mock data.\")\n",
    "    X = pd.DataFrame(np.random.rand(100, 10), columns=[f'Feature_{i}' for i in range(10)])\n",
    "if 'Y' not in locals() and 'Y' not in globals():\n",
    "    print(\"Warning: Variable 'Y' is not defined. Using mock data.\")\n",
    "    Y = pd.Series(np.random.rand(100))\n",
    "if 'grid_searches' not in locals() and 'grid_searches' not in globals():\n",
    "    print(\"Warning: Variable 'grid_searches' is not defined. Using default (unoptimized) models.\")\n",
    "    grid_searches = {\n",
    "        'XGBR': type('obj', (object,), {'best_estimator_': XGB.XGBRegressor(random_state=DEFAULT_MODEL_RANDOM_STATE, objective='reg:squarederror')})(),\n",
    "        'RF': type('obj', (object,), {'best_estimator_': RandomForestRegressor(random_state=DEFAULT_MODEL_RANDOM_STATE)})(),\n",
    "        'GBRT': type('obj', (object,), {'best_estimator_': GradientBoostingRegressor(random_state=DEFAULT_MODEL_RANDOM_STATE)})(),\n",
    "        'ETR': type('obj', (object,), {'best_estimator_': ExtraTreesRegressor(random_state=DEFAULT_MODEL_RANDOM_STATE)})(),\n",
    "        'HGBR': type('obj', (object,), {'best_estimator_': HistGradientBoostingRegressor(random_state=DEFAULT_MODEL_RANDOM_STATE)})()\n",
    "    }\n",
    "    if catboost_available:\n",
    "        grid_searches['CBR'] = type('obj', (object,), {'best_estimator_': CatBoostRegressor(verbose=False, random_state=DEFAULT_MODEL_RANDOM_STATE, allow_writing_files=False)})()\n",
    "    if lightgbm_available:\n",
    "        grid_searches['LGBM'] = type('obj', (object,), {'best_estimator_': LGBMRegressor(random_state=DEFAULT_MODEL_RANDOM_STATE, verbosity=-1, objective='regression')})()\n",
    "\n",
    "# Filter models to be used based on user configuration\n",
    "filtered_grid_searches = {name: gs for name, gs in grid_searches.items() if name in ENABLED_BASE_LEARNERS and gs is not None}\n",
    "print(f\"\\nModel filtering complete: Selected {len(filtered_grid_searches)} enabled models from {len(grid_searches)} available models: {list(filtered_grid_searches.keys())}\")\n",
    "if not filtered_grid_searches:\n",
    "    print(\"\\n!!! Fatal Error: No base learners were selected. Please check the ENABLED_BASE_LEARNERS list in the configuration.\")\n",
    "    exit()\n",
    "\n",
    "# Data Format Check and Preparation\n",
    "try:\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        print(\"Warning: For accurate sample indexing, it is recommended that the input X is a Pandas DataFrame.\")\n",
    "        X_index = pd.RangeIndex(start=0, stop=len(X), step=1)\n",
    "    else:\n",
    "        X_index = X.index\n",
    "    if len(Y) != len(X): raise ValueError(\"Length of X and Y do not match!\")\n",
    "    if isinstance(Y, pd.DataFrame):\n",
    "        if Y.shape[1] != 1: raise ValueError(\"If Y is a DataFrame, it should contain only one target column.\")\n",
    "        if not Y.index.equals(X_index): print(\"Warning: The index of Y does not match the index of X.\")\n",
    "        Y = Y.iloc[:, 0]\n",
    "except NameError as e:\n",
    "    print(f\"Error: {e}. Please ensure the optimization script has been run or the required variables are loaded.\")\n",
    "    exit()\n",
    "except ValueError as e:\n",
    "    print(f\"Data Error: {e}\")\n",
    "    exit()\n",
    "\n",
    "if NOISE_SCALE_FACTOR > 0:\n",
    "    print(f\"Gaussian noise augmentation is enabled with a strength factor of: {NOISE_SCALE_FACTOR}\")\n",
    "else:\n",
    "    print(\"Noise augmentation is disabled.\")\n",
    "np.random.seed(DEFAULT_MODEL_RANDOM_STATE)\n",
    "\n",
    "\n",
    "# --- 3. Core Function Definitions ---\n",
    "def initialize_best_estimators(grid_searches_dict):\n",
    "    \"\"\"Initialize model instances from BayesSearchCV results.\"\"\"\n",
    "    estimators_init = {}\n",
    "    available_models = {\n",
    "        'XGBR': (XGB.XGBRegressor, {'objective': 'reg:squarederror', 'random_state': DEFAULT_MODEL_RANDOM_STATE}),\n",
    "        'RF': (RandomForestRegressor, {'random_state': DEFAULT_MODEL_RANDOM_STATE}),\n",
    "        'GBRT': (GradientBoostingRegressor, {'random_state': DEFAULT_MODEL_RANDOM_STATE}),\n",
    "        'ETR': (ExtraTreesRegressor, {'random_state': DEFAULT_MODEL_RANDOM_STATE}),\n",
    "        'HGBR': (HistGradientBoostingRegressor, {'random_state': DEFAULT_MODEL_RANDOM_STATE})\n",
    "    }\n",
    "    if catboost_available: available_models['CBR'] = (CatBoostRegressor, {'verbose': False, 'random_state': DEFAULT_MODEL_RANDOM_STATE, 'allow_writing_files': False})\n",
    "    if lightgbm_available: available_models['LGBM'] = (LGBMRegressor, {'random_state': DEFAULT_MODEL_RANDOM_STATE, 'verbosity': -1, 'objective': 'regression'})\n",
    "\n",
    "    print(\"Initializing models...\")\n",
    "    for name in grid_searches_dict.keys():\n",
    "        if name not in available_models: continue\n",
    "        model_class, fixed_params = available_models[name]\n",
    "        if name in grid_searches_dict and hasattr(grid_searches_dict[name], 'best_estimator_'):\n",
    "            try:\n",
    "                estimators_init[name] = clone(grid_searches_dict[name].best_estimator_)\n",
    "                print(f\"  Successfully initialized {name} with optimized parameters.\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error initializing {name} from best_estimator_: {e}. This model will be skipped.\")\n",
    "                estimators_init[name] = None\n",
    "        else:\n",
    "            print(f\"  Optimized results for {name} not found. Initializing with default parameters.\")\n",
    "            try:\n",
    "                estimators_init[name] = model_class(**fixed_params)\n",
    "                print(f\"  Successfully initialized {name} with default parameters.\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error initializing {name} with default parameters: {e}. This model will be skipped.\")\n",
    "                estimators_init[name] = None\n",
    "    \n",
    "    initialized_estimators = {k: v for k, v in estimators_init.items() if v is not None}\n",
    "    \n",
    "    if not initialized_estimators: print(\"Warning: No models were successfully initialized!\")\n",
    "    return initialized_estimators\n",
    "\n",
    "meta_learner_params = {\n",
    "    'elasticnet__alpha': Real(1e-5, 10.0, prior='log-uniform', name='elasticnet__alpha'),\n",
    "    'elasticnet__l1_ratio': Real(0.0, 1.0, prior='uniform', name='elasticnet__l1_ratio')\n",
    "}\n",
    "global_best_meta_learner = None\n",
    "global_meta_learner_coeffs = None\n",
    "\n",
    "def evaluate_models_manual_cv(seed, X_full, Y_full, X_full_index, grid_searches_dict, noise_factor, meta_learner_instance=None):\n",
    "    \"\"\"Manually execute one full cross-validation evaluation process.\"\"\"\n",
    "    print(f\"\\n--- Starting Seed {seed} ---\")\n",
    "    cross_validator = KFold(n_splits=N_SPLITS_OUTER_CV, shuffle=True, random_state=seed)\n",
    "    best_estimators_dict = initialize_best_estimators(grid_searches_dict)\n",
    "    if not best_estimators_dict:\n",
    "        return {'submodel_r2_means': {}, 'submodel_rmse_means': {}, 'stacking_regressor_r2_mean': np.nan, 'stacking_regressor_rmse_mean': np.nan, 'plot_data': [], 'meta_learner_coefficients': {}, 'raw_shap_values': {}, 'shap_expected_values': {}, 'X_val_data_for_shap': [], 'all_scores_data_for_seed_fold': []}\n",
    "\n",
    "    submodels = list(best_estimators_dict.items())\n",
    "    submodel_names = [name for name, _ in submodels]\n",
    "    fold_r2_scores = {name: [] for name in submodel_names}; fold_rmse_scores = {name: [] for name in submodel_names}\n",
    "    fold_r2_scores['Stacking'] = []; fold_rmse_scores['Stacking'] = []\n",
    "    all_plot_data_for_seed, all_scores_data_for_seed_fold = [], []\n",
    "    \n",
    "    meta_coefficients_sum_current_seed, meta_coefficients_count_current_seed = np.zeros(len(submodel_names)), 0\n",
    "    all_raw_shap_values_per_model = {name: [] for name in submodel_names}\n",
    "    all_shap_expected_values_per_model = {name: [] for name in submodel_names}\n",
    "    all_X_val_data_for_shap_folds = []\n",
    "\n",
    "    print(f\"  Seed {seed}: Starting {N_SPLITS_OUTER_CV}-fold cross-validation (Outer CV)...\")\n",
    "    is_X_dataframe = isinstance(X_full, pd.DataFrame)\n",
    "    original_columns = X_full.columns if is_X_dataframe else [f'Feature_{i}' for i in range(X_full.shape[1])]\n",
    "    \n",
    "    for fold_idx, (train_loc_idx, val_loc_idx) in enumerate(cross_validator.split(X_full, Y_full)):\n",
    "        train_original_indices, val_original_indices = X_full_index[train_loc_idx], X_full_index[val_loc_idx]\n",
    "        if is_X_dataframe:\n",
    "            X_train_fold, X_val_fold = X_full.loc[train_original_indices], X_full.loc[val_original_indices]\n",
    "            Y_train_fold, Y_val_fold = Y_full.loc[train_original_indices], Y_full.loc[val_original_indices]\n",
    "        else:\n",
    "            X_train_fold, X_val_fold = X_full[train_loc_idx], X_full[val_loc_idx]\n",
    "            Y_train_fold, Y_val_fold = Y_full[train_loc_idx], Y_full[val_loc_idx]\n",
    "        \n",
    "        y_val_true_np = Y_val_fold.values if isinstance(Y_val_fold, pd.Series) else np.array(Y_val_fold)\n",
    "        y_train_true_np = Y_train_fold.values if isinstance(Y_train_fold, pd.Series) else np.array(Y_train_fold)\n",
    "        \n",
    "        X_train_augmented = X_train_fold\n",
    "        if noise_factor > 0:\n",
    "            X_train_fold_np = X_train_fold.values if is_X_dataframe else X_train_fold\n",
    "            noise = np.random.normal(loc=0.0, scale=np.std(X_train_fold_np, axis=0) * noise_factor + 1e-9, size=X_train_fold_np.shape)\n",
    "            X_train_augmented = pd.DataFrame(X_train_fold_np + noise, index=train_original_indices, columns=original_columns) if is_X_dataframe else X_train_fold_np + noise\n",
    "        \n",
    "        oof_preds_train, oof_preds_val = np.zeros((len(Y_train_fold), len(submodels))), np.zeros((len(Y_val_fold), len(submodels)))\n",
    "        all_X_val_data_for_shap_folds.append(X_val_fold)\n",
    "\n",
    "        for i, (name, estimator_template) in enumerate(submodels):\n",
    "            estimator_fold = clone(estimator_template)\n",
    "            try:\n",
    "                estimator_fold.fit(X_train_augmented, Y_train_fold)\n",
    "            except Exception as fit_e:\n",
    "                print(f\"\\nWarning: Seed {seed}, Fold {fold_idx+1}, model {name} failed to fit: {fit_e}\")\n",
    "                oof_preds_train[:, i], oof_preds_val[:, i] = 0, 0\n",
    "                all_scores_data_for_seed_fold.extend([{'Seed': seed, 'Fold': fold_idx + 1, 'Model': name, 'Metric': 'R2', 'Value': np.nan}, {'Seed': seed, 'Fold': fold_idx + 1, 'Model': name, 'Metric': 'RMSE', 'Value': np.nan}])\n",
    "                continue\n",
    "\n",
    "            oof_preds_train[:, i] = estimator_fold.predict(X_train_fold)\n",
    "            oof_preds_val[:, i] = estimator_fold.predict(X_val_fold)\n",
    "            r2 = r2_score(Y_val_fold, oof_preds_val[:, i]); rmse = np.sqrt(mean_squared_error(Y_val_fold, oof_preds_val[:, i]))\n",
    "            fold_r2_scores[name].append(r2); fold_rmse_scores[name].append(rmse)\n",
    "            all_scores_data_for_seed_fold.extend([{'Seed': seed, 'Fold': fold_idx + 1, 'Model': name, 'Metric': 'R2', 'Value': r2}, {'Seed': seed, 'Fold': fold_idx + 1, 'Model': name, 'Metric': 'RMSE', 'Value': rmse}])\n",
    "            \n",
    "            for idx, (actual, pred) in enumerate(zip(y_val_true_np, oof_preds_val[:, i])): all_plot_data_for_seed.append({'Seed': seed, 'Fold': fold_idx + 1, 'Model': name, 'Set': 'Validation', 'Actual': actual, 'Predicted': pred, 'Sample_Index': val_original_indices[idx]})\n",
    "            for idx, (actual, pred) in enumerate(zip(y_train_true_np, oof_preds_train[:, i])): all_plot_data_for_seed.append({'Seed': seed, 'Fold': fold_idx + 1, 'Model': name, 'Set': 'Train', 'Actual': actual, 'Predicted': pred, 'Sample_Index': train_original_indices[idx]})\n",
    "\n",
    "            try:\n",
    "                X_val_fold_np = X_val_fold.values if isinstance(X_val_fold, pd.DataFrame) else X_val_fold\n",
    "                if X_val_fold_np.shape[0] == 0: continue\n",
    "                if isinstance(estimator_fold, (XGB.XGBRegressor, RandomForestRegressor, GradientBoostingRegressor, CatBoostRegressor, LGBMRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor)):\n",
    "                    explainer = shap.TreeExplainer(estimator_fold)\n",
    "                    shap_values = explainer.shap_values(X_val_fold_np); expected_value = explainer.expected_value\n",
    "                else: continue\n",
    "                all_raw_shap_values_per_model[name].append(shap_values); all_shap_expected_values_per_model[name].append(expected_value)\n",
    "            except Exception as imp_e: print(f\"\\nWarning: Seed {seed}, Fold {fold_idx+1}, error getting SHAP values for {name}: {imp_e}\")\n",
    "\n",
    "        if np.all(oof_preds_train == 0) or np.any(np.isnan(oof_preds_train)):\n",
    "            print(f\"Warning: Seed {seed}, Fold {fold_idx+1}, OOF predictions are invalid. Skipping meta-learner.\")\n",
    "            fold_r2_scores['Stacking'].append(np.nan); fold_rmse_scores['Stacking'].append(np.nan)\n",
    "            all_scores_data_for_seed_fold.extend([{'Seed': seed, 'Fold': fold_idx + 1, 'Model': 'Stacking', 'Metric': 'R2', 'Value': np.nan}, {'Seed': seed, 'Fold': fold_idx + 1, 'Model': 'Stacking', 'Metric': 'RMSE', 'Value': np.nan}])\n",
    "            continue\n",
    "\n",
    "        current_meta_learner = None\n",
    "        if meta_learner_instance:\n",
    "            current_meta_learner = clone(meta_learner_instance)\n",
    "            current_meta_learner.fit(oof_preds_train, Y_train_fold) \n",
    "        else:\n",
    "            print(f\"  Seed {seed}, Fold {fold_idx+1}: Tuning meta-learner...\")\n",
    "            res_meta = BayesSearchCV(estimator=Pipeline([('scaler', StandardScaler()), ('elasticnet', ElasticNet(random_state=DEFAULT_MODEL_RANDOM_STATE, max_iter=2000))]), search_spaces=meta_learner_params, n_iter=META_LEARNER_N_ITER_BAYESIAN, scoring='r2', cv=RepeatedKFold(n_splits=META_LEARNER_N_SPLITS_CV, n_repeats=META_LEARNER_N_REPEATS_CV, random_state=DEFAULT_MODEL_RANDOM_STATE), n_jobs=-1, random_state=DEFAULT_MODEL_RANDOM_STATE, verbose=0)\n",
    "            try:\n",
    "                res_meta.fit(oof_preds_train, Y_train_fold)\n",
    "                current_meta_learner = res_meta.best_estimator_\n",
    "            except Exception as meta_e: print(f\"\\nWarning: Seed {seed}, Fold {fold_idx+1}, meta-learner tuning failed: {meta_e}\")\n",
    "\n",
    "        if current_meta_learner:\n",
    "            try:\n",
    "                elastic_net_model = current_meta_learner.named_steps['elasticnet']\n",
    "                meta_coefficients_sum_current_seed += elastic_net_model.coef_; meta_coefficients_count_current_seed += 1\n",
    "                y_pred_val_stacking = current_meta_learner.predict(oof_preds_val); y_pred_train_stacking = current_meta_learner.predict(oof_preds_train)\n",
    "                r2_stacking = r2_score(Y_val_fold, y_pred_val_stacking); rmse_stacking = np.sqrt(mean_squared_error(Y_val_fold, y_pred_val_stacking))\n",
    "                fold_r2_scores['Stacking'].append(r2_stacking); fold_rmse_scores['Stacking'].append(rmse_stacking)\n",
    "                all_scores_data_for_seed_fold.extend([{'Seed': seed, 'Fold': fold_idx + 1, 'Model': 'Stacking', 'Metric': 'R2', 'Value': r2_stacking}, {'Seed': seed, 'Fold': fold_idx + 1, 'Model': 'Stacking', 'Metric': 'RMSE', 'Value': rmse_stacking}])\n",
    "                for idx, (actual, pred) in enumerate(zip(y_val_true_np, y_pred_val_stacking)): all_plot_data_for_seed.append({'Seed': seed, 'Fold': fold_idx + 1, 'Model': 'Stacking', 'Set': 'Validation', 'Actual': actual, 'Predicted': pred, 'Sample_Index': val_original_indices[idx]})\n",
    "                for idx, (actual, pred) in enumerate(zip(y_train_true_np, y_pred_train_stacking)): all_plot_data_for_seed.append({'Seed': seed, 'Fold': fold_idx + 1, 'Model': 'Stacking', 'Set': 'Train', 'Actual': actual, 'Predicted': pred, 'Sample_Index': train_original_indices[idx]})\n",
    "            except Exception as meta_e: \n",
    "                print(f\"\\nWarning: Seed {seed}, Fold {fold_idx+1}, meta-learner prediction failed: {meta_e}\")\n",
    "                fold_r2_scores['Stacking'].append(np.nan); fold_rmse_scores['Stacking'].append(np.nan)\n",
    "        \n",
    "    submodel_r2_means = {name: np.nanmean(scores) if scores else np.nan for name, scores in fold_r2_scores.items()}\n",
    "    submodel_rmse_means = {name: np.nanmean(scores) if scores else np.nan for name, scores in fold_rmse_scores.items()}\n",
    "    stacking_regressor_r2_mean = submodel_r2_means.pop('Stacking', np.nan)\n",
    "    stacking_regressor_rmse_mean = submodel_rmse_means.pop('Stacking', np.nan)\n",
    "    avg_meta_coefficients_current_seed = dict(zip(submodel_names, meta_coefficients_sum_current_seed / meta_coefficients_count_current_seed)) if meta_coefficients_count_current_seed > 0 else {}\n",
    "    \n",
    "    return {'submodel_r2_means': submodel_r2_means, 'submodel_rmse_means': submodel_rmse_means, 'stacking_regressor_r2_mean': stacking_regressor_r2_mean, 'stacking_regressor_rmse_mean': stacking_regressor_rmse_mean, 'plot_data': all_plot_data_for_seed, 'meta_learner_coefficients': avg_meta_coefficients_current_seed, 'raw_shap_values': all_raw_shap_values_per_model, 'shap_expected_values': all_shap_expected_values_per_model, 'X_val_data_for_shap': all_X_val_data_for_shap_folds, 'all_scores_data_for_seed_fold': all_scores_data_for_seed_fold}\n",
    "\n",
    "\n",
    "# --- 4. Main Execution Flow ---\n",
    "if isinstance(X, pd.DataFrame):\n",
    "    feature_names_list = X.columns.tolist()\n",
    "else:\n",
    "    feature_names_list = [f'Feature_{i}' for i in range(X.shape[1])]\n",
    "\n",
    "all_results, all_plot_data_accumulated, all_scores_accumulated = [], [], []\n",
    "seeds = range(N_SEEDS_FOR_EVALUATION)\n",
    "model_names_available = list(filtered_grid_searches.keys())\n",
    "submodel_r2_sums = {name: 0.0 for name in model_names_available}; submodel_rmse_sums = {name: 0.0 for name in model_names_available}\n",
    "stacking_r2_sum, stacking_rmse_sum = 0.0, 0.0\n",
    "meta_coefficients_sums_across_seeds = {name: 0.0 for name in model_names_available}\n",
    "valid_seeds_count = 0\n",
    "all_aggregated_shap_values_for_swarm_raw_data = []\n",
    "\n",
    "print(f\"\\n=== Starting Repeated Cross-Validation on {len(seeds)} Different Seeds ===\")\n",
    "for seed in seeds:\n",
    "    if seed == 0:\n",
    "        print(\"\\n--- First Iteration (Seed 0): Tuning Meta-Learner Hyperparameters ---\")\n",
    "        oof_preds_full = np.zeros((len(X), len(model_names_available)))\n",
    "        kf_full_data = KFold(n_splits=N_SPLITS_OUTER_CV, shuffle=True, random_state=seed)\n",
    "        temp_base_estimators = initialize_best_estimators(filtered_grid_searches)\n",
    "        if not temp_base_estimators: print(\"Warning: Could not initialize base learners, skipping meta-learner tuning.\"); break\n",
    "        for i, (name, estimator_template) in enumerate(temp_base_estimators.items()):\n",
    "            print(f\"  Generating OOF predictions for model {name}...\")\n",
    "            fold_preds = np.zeros(len(X))\n",
    "            for train_idx, val_idx in kf_full_data.split(X, Y):\n",
    "                X_train_fold, X_val_fold = (X.iloc[train_idx], X.iloc[val_idx]) if isinstance(X, pd.DataFrame) else (X[train_idx], X[val_idx])\n",
    "                Y_train_fold = Y.iloc[train_idx] if isinstance(Y, pd.Series) else Y[train_idx]\n",
    "                estimator_clone = clone(estimator_template); estimator_clone.fit(X_train_fold, Y_train_fold)\n",
    "                fold_preds[val_idx] = estimator_clone.predict(X_val_fold)\n",
    "            oof_preds_full[:, i] = fold_preds\n",
    "        \n",
    "        if np.all(oof_preds_full == 0) or np.any(np.isnan(oof_preds_full)):\n",
    "            print(\"Warning: Generated OOF predictions are invalid. Cannot tune meta-learner.\")\n",
    "            global_best_meta_learner, global_meta_learner_coeffs = None, {name: np.nan for name in model_names_available}\n",
    "            result = evaluate_models_manual_cv(seed, X, Y, X_index, filtered_grid_searches, NOISE_SCALE_FACTOR, meta_learner_instance=None)\n",
    "        else:\n",
    "            print(\"  Starting Bayesian Optimization for the meta-learner...\")\n",
    "            meta_bayes_search = BayesSearchCV(\n",
    "                estimator=Pipeline([('scaler', StandardScaler()), ('elasticnet', ElasticNet(random_state=DEFAULT_MODEL_RANDOM_STATE, max_iter=2000))]),\n",
    "                search_spaces=meta_learner_params, n_iter=META_LEARNER_N_ITER_BAYESIAN, scoring='r2',\n",
    "                cv=RepeatedKFold(n_splits=META_LEARNER_N_SPLITS_CV, n_repeats=META_LEARNER_N_REPEATS_CV, random_state=DEFAULT_MODEL_RANDOM_STATE),\n",
    "                n_jobs=-1, random_state=DEFAULT_MODEL_RANDOM_STATE, verbose=1)\n",
    "            try:\n",
    "                meta_bayes_search.fit(oof_preds_full, Y)\n",
    "                global_best_meta_learner = meta_bayes_search.best_estimator_\n",
    "                elastic_net_model = global_best_meta_learner.named_steps['elasticnet']\n",
    "                global_meta_learner_coeffs = dict(zip(model_names_available, elastic_net_model.coef_))\n",
    "                print(\"\\n--- Meta-Learner tuning complete ---\"); print(f\"Meta-Learner Best Score (CV R² on Full OOF): {meta_bayes_search.best_score_:.4f}\"); print(f\"Meta-Learner Best Parameters: {dict(meta_bayes_search.best_params_)}\"); print(f\"Meta-Learner Coefficients: {global_meta_learner_coeffs}\")\n",
    "                result = evaluate_models_manual_cv(seed, X, Y, X_index, filtered_grid_searches, NOISE_SCALE_FACTOR, meta_learner_instance=global_best_meta_learner)\n",
    "            except Exception as e:\n",
    "                print(f\"\\n!!! Meta-learner tuning failed: {e}\")\n",
    "                global_best_meta_learner, global_meta_learner_coeffs = None, {name: np.nan for name in model_names_available}\n",
    "                result = evaluate_models_manual_cv(seed, X, Y, X_index, filtered_grid_searches, NOISE_SCALE_FACTOR, meta_learner_instance=None)\n",
    "    else:\n",
    "        print(f\"\\n--- Subsequent Iteration (Seed {seed}): Using pre-tuned meta-learner ---\")\n",
    "        result = evaluate_models_manual_cv(seed, X, Y, X_index, filtered_grid_searches, NOISE_SCALE_FACTOR, meta_learner_instance=global_best_meta_learner)\n",
    "\n",
    "    all_results.append(result)\n",
    "    if result.get('plot_data'): all_plot_data_accumulated.extend(result['plot_data'])\n",
    "    if result.get('all_scores_data_for_seed_fold'): all_scores_accumulated.extend(result['all_scores_data_for_seed_fold'])\n",
    "    \n",
    "    print(f\"\\n--- Seed {seed} Results Summary ---\")\n",
    "    current_stacking_r2 = result.get('stacking_regressor_r2_mean', np.nan)\n",
    "    current_stacking_rmse = result.get('stacking_regressor_rmse_mean', np.nan)\n",
    "    sr_r2_str = f\"{current_stacking_r2:.4f}\" if not np.isnan(current_stacking_r2) else \"N/A\"\n",
    "    sr_rmse_str = f\"{current_stacking_rmse:.4f}\" if not np.isnan(current_stacking_rmse) else \"N/A\"\n",
    "    print(f\"  Stacking Regressor R2 Mean: {sr_r2_str}\"); print(f\"  Stacking Regressor RMSE Mean: {sr_rmse_str}\")\n",
    "    print(\"  Submodel R2 and RMSE Means:\")\n",
    "    current_sub_r2 = result.get('submodel_r2_means', {})\n",
    "    current_sub_rmse = result.get('submodel_rmse_means', {})\n",
    "    for name in model_names_available:\n",
    "        r2_val, rmse_val = current_sub_r2.get(name, np.nan), current_sub_rmse.get(name, np.nan)\n",
    "        r2_str = f\"{r2_val:.4f}\" if not np.isnan(r2_val) else \"N/A\"; rmse_str = f\"{rmse_val:.4f}\" if not np.isnan(rmse_val) else \"N/A\"\n",
    "        print(f\"      {name}: R2 Mean = {r2_str}, RMSE Mean = {rmse_str}\")\n",
    "    if global_meta_learner_coeffs:\n",
    "        print(\"  Meta-Learner Coefficients (Fixed after Seed 0):\")\n",
    "        for name, coeff in global_meta_learner_coeffs.items(): print(f\"      {name}: {coeff:.4f}\")\n",
    "    \n",
    "    if PLOT_SHAP_SWARM_PLOT and result.get('raw_shap_values') and result.get('X_val_data_for_shap'):\n",
    "        for model_name in model_names_available:\n",
    "            if model_name in result['raw_shap_values']:\n",
    "                for i in range(len(result['raw_shap_values'][model_name])):\n",
    "                    if i < len(result['X_val_data_for_shap']):\n",
    "                        all_aggregated_shap_values_for_swarm_raw_data.append({'seed': seed, 'fold_idx': i, 'model_name': model_name, 'shap_values': result['raw_shap_values'][model_name][i], 'expected_value': result['shap_expected_values'][model_name][i], 'X_val_data': result['X_val_data_for_shap'][i]})\n",
    "\n",
    "    if not np.isnan(current_stacking_r2):\n",
    "        valid_seeds_count += 1\n",
    "        stacking_r2_sum += current_stacking_r2\n",
    "        stacking_rmse_sum += result.get('stacking_regressor_rmse_mean', np.nan)\n",
    "        for name in model_names_available:\n",
    "            submodel_r2_sums[name] += result.get('submodel_r2_means', {}).get(name, np.nan)\n",
    "            submodel_rmse_sums[name] += result.get('submodel_rmse_means', {}).get(name, np.nan)\n",
    "        if global_meta_learner_coeffs:\n",
    "            for name, coeff in global_meta_learner_coeffs.items(): meta_coefficients_sums_across_seeds[name] += coeff\n",
    "    else: print(f\"Warning: Stacking Regressor result for Seed {seed} is NaN. Skipping accumulation.\")\n",
    "\n",
    "# --- 5. Final Results Visualization and Export ---\n",
    "if valid_seeds_count > 0:\n",
    "    avg_stacking_regressor_r2_mean = stacking_r2_sum / valid_seeds_count\n",
    "    avg_stacking_regressor_rmse_mean = stacking_rmse_sum / valid_seeds_count\n",
    "    avg_submodel_r2_means = {name: total / valid_seeds_count for name, total in submodel_r2_sums.items()}\n",
    "    avg_submodel_rmse_means = {name: total / valid_seeds_count for name, total in submodel_rmse_sums.items()}\n",
    "    avg_meta_coefficients_final = {name: total / valid_seeds_count for name, total in meta_coefficients_sums_across_seeds.items()} if global_meta_learner_coeffs else {name: np.nan for name in model_names_available}\n",
    "    \n",
    "    print(f\"\\n\\n==============================================================================\")\n",
    "    print(f\"--- Average Results Across All {valid_seeds_count} Valid Seeds ---\")\n",
    "    print(f\"==============================================================================\")\n",
    "    print(f\"\\nAverage Stacking Regressor R2 Mean: {avg_stacking_regressor_r2_mean:.4f}\")\n",
    "    print(f\"Average Stacking Regressor RMSE Mean: {avg_stacking_regressor_rmse_mean:.4f}\")\n",
    "    print(\"\\nAverage Submodel R2 and RMSE Means:\")\n",
    "    for name in model_names_available:\n",
    "        r2_avg, rmse_avg = avg_submodel_r2_means.get(name, np.nan), avg_submodel_rmse_means.get(name, np.nan)\n",
    "        print(f\"  {name}: R2 Mean = {r2_avg:.4f}, RMSE Mean = {rmse_avg:.4f}\")\n",
    "    \n",
    "    print(\"\\nAverage Meta-Learner Coefficients (Averaged over Seeds):\")\n",
    "    for name, coeff in avg_meta_coefficients_final.items(): print(f\"  {name}: {coeff:.4f}\")\n",
    "\n",
    "    # =================================================================================\n",
    "    # --- Two-Level Weighted SHAP Analysis Module ---\n",
    "    # =================================================================================\n",
    "    if PLOT_SHAP_SWARM_PLOT and all_aggregated_shap_values_for_swarm_raw_data and all_scores_accumulated:\n",
    "        print(\"\\n--- Performing [Two-Level Weighted] SHAP Aggregation and Feature Importance Analysis ---\")\n",
    "        print(\"    Level 1: Within each training fold, weight by the base model's R².\")\n",
    "        print(\"    Level 2: Across all training folds, weight by the Stacking model's R².\")\n",
    "\n",
    "        try:\n",
    "            # 1. Prepare data\n",
    "            scores_df = pd.DataFrame(all_scores_accumulated)\n",
    "            scores_pivot = scores_df.pivot_table(index=['Seed', 'Fold'], columns=['Model', 'Metric'], values='Value')\n",
    "            \n",
    "            grouped_shap_data = {}\n",
    "            for item in all_aggregated_shap_values_for_swarm_raw_data:\n",
    "                key = (item['seed'], item['fold_idx'])\n",
    "                if key not in grouped_shap_data:\n",
    "                    grouped_shap_data[key] = {'models_data': {}, 'X_val_data': item['X_val_data']}\n",
    "                grouped_shap_data[key]['models_data'][item['model_name']] = {'shap_values': item['shap_values'], 'expected_value': item['expected_value']}\n",
    "\n",
    "            # 2. Perform two-level weighting\n",
    "            level1_weighted_shap_list, level1_weighted_expected_values_list = [], []\n",
    "            level1_X_data_list, level2_weights_list = [], []\n",
    "            \n",
    "            print(\"  Iterating through all Seeds and Folds to calculate weighted SHAP values...\")\n",
    "            for (seed, fold_idx), data in grouped_shap_data.items():\n",
    "                models_data_in_fold = data['models_data']\n",
    "                \n",
    "                # Level 1 Weighting (within a fold)\n",
    "                base_model_r2s = {}\n",
    "                valid_models_in_fold = list(models_data_in_fold.keys())\n",
    "                for model_name in valid_models_in_fold:\n",
    "                    try:\n",
    "                        r2_tuple = (model_name, 'R2')\n",
    "                        r2 = scores_pivot.loc[(seed, fold_idx + 1), r2_tuple]\n",
    "                        base_model_r2s[model_name] = max(0, r2) if not np.isnan(r2) else 0.0\n",
    "                    except KeyError:\n",
    "                        base_model_r2s[model_name] = 0.0\n",
    "\n",
    "                total_r2_sum_level1 = sum(base_model_r2s.values())\n",
    "                if total_r2_sum_level1 < 1e-9: continue\n",
    "\n",
    "                first_valid_shap, first_valid_X = None, None\n",
    "                for model_name in valid_models_in_fold:\n",
    "                    if models_data_in_fold[model_name]['shap_values'].shape[0] > 0:\n",
    "                        first_valid_shap = models_data_in_fold[model_name]['shap_values']\n",
    "                        first_valid_X = data['X_val_data']\n",
    "                        break\n",
    "                if first_valid_shap is None: continue\n",
    "\n",
    "                weighted_shap_for_fold = np.zeros_like(first_valid_shap)\n",
    "                weighted_expected_value_for_fold = 0.0\n",
    "                for model_name, model_data in models_data_in_fold.items():\n",
    "                    if model_data['shap_values'].shape == weighted_shap_for_fold.shape:\n",
    "                        weight = base_model_r2s.get(model_name, 0.0) / total_r2_sum_level1\n",
    "                        weighted_shap_for_fold += weight * model_data['shap_values']\n",
    "                        weighted_expected_value_for_fold += weight * model_data['expected_value']\n",
    "                \n",
    "                # Level 2 Weight (across folds)\n",
    "                try:\n",
    "                    stacking_r2_tuple = ('Stacking', 'R2')\n",
    "                    level2_weight = scores_pivot.loc[(seed, fold_idx + 1), stacking_r2_tuple]\n",
    "                    level2_weight = max(0, level2_weight) if not np.isnan(level2_weight) else 0.0\n",
    "                except KeyError:\n",
    "                    level2_weight = 0.0\n",
    "\n",
    "                level1_weighted_shap_list.append(weighted_shap_for_fold)\n",
    "                level1_weighted_expected_values_list.append(weighted_expected_value_for_fold)\n",
    "                level1_X_data_list.append(first_valid_X)\n",
    "                level2_weights_list.append(level2_weight)\n",
    "\n",
    "            # 3. Aggregate all data and apply level 2 weighting\n",
    "            if level1_weighted_shap_list:\n",
    "                print(\"  Aggregating data from all folds and applying Level 2 weights...\")\n",
    "                final_shap_values_for_plot = np.vstack(level1_weighted_shap_list)\n",
    "                final_X_data_for_plot = pd.concat(level1_X_data_list, ignore_index=True)\n",
    "                \n",
    "                sample_weights_level2 = np.repeat(level2_weights_list, [matrix.shape[0] for matrix in level1_weighted_shap_list])\n",
    "\n",
    "                sample_indices = slice(None)\n",
    "                if SHAP_SWARM_SAMPLES_LIMIT is not None and final_shap_values_for_plot.shape[0] > SHAP_SWARM_SAMPLES_LIMIT:\n",
    "                    print(f\"  Warning: Number of SHAP samples is too large ({final_shap_values_for_plot.shape[0]}). Subsampling to {SHAP_SWARM_SAMPLES_LIMIT}.\")\n",
    "                    rng = np.random.default_rng(DEFAULT_MODEL_RANDOM_STATE)\n",
    "                    sample_indices = rng.choice(final_shap_values_for_plot.shape[0], SHAP_SWARM_SAMPLES_LIMIT, replace=False)\n",
    "                    final_shap_values_for_plot = final_shap_values_for_plot[sample_indices]\n",
    "                    final_X_data_for_plot = final_X_data_for_plot.iloc[sample_indices]\n",
    "                    sample_weights_level2 = sample_weights_level2[sample_indices]\n",
    "\n",
    "                if np.sum(sample_weights_level2) > 1e-9:\n",
    "                    expected_values_per_sample = np.repeat(level1_weighted_expected_values_list, [matrix.shape[0] for matrix in level1_weighted_shap_list])\n",
    "                    if isinstance(sample_indices, np.ndarray):\n",
    "                        expected_values_per_sample = expected_values_per_sample[sample_indices]\n",
    "\n",
    "                    final_base_value = np.average(expected_values_per_sample, weights=sample_weights_level2)\n",
    "\n",
    "                    # 4. Calculate unified feature importance\n",
    "                    print(\"\\n--- Unified Feature Importance Results (from Two-Level Weighted SHAP data) ---\")\n",
    "                    unified_feature_importances = pd.Series(\n",
    "                        np.average(np.abs(final_shap_values_for_plot), axis=0, weights=sample_weights_level2),\n",
    "                        index=feature_names_list\n",
    "                    )\n",
    "                    sorted_feature_importances = sorted(unified_feature_importances.to_dict().items(), key=lambda item: item[1], reverse=True)\n",
    "                    \n",
    "                    print(\"Global Feature Importances (sorted):\")\n",
    "                    for feature, importance in sorted_feature_importances:\n",
    "                        print(f\"  {feature}: {importance:.4f}\")\n",
    "\n",
    "                    # 5. Plot unified feature importance bar chart\n",
    "                    print(\"\\nPlotting unified feature importance bar chart...\")\n",
    "                    features_to_plot = [item[0] for item in sorted_feature_importances[:N_FEATURES_TO_PLOT]]\n",
    "                    importances_to_plot = [item[1] for item in sorted_feature_importances[:N_FEATURES_TO_PLOT]]\n",
    "                    plt.figure(figsize=(10, max(6, N_FEATURES_TO_PLOT * 0.4))); \n",
    "                    sns.barplot(x=importances_to_plot, y=features_to_plot, palette=\"viridis_r\")\n",
    "                    plt.xlabel('Unified Feature Importance (Two-Level Weighted Mean Absolute SHAP)'); \n",
    "                    plt.ylabel('Feature'); \n",
    "                    plt.title(f'Top {N_FEATURES_TO_PLOT} Feature Importances from Two-Level Weighted SHAP'); \n",
    "                    plt.tight_layout()\n",
    "                    plot_filename = f'unified_feature_importances_2level_weighted_{time.strftime(\"%Y%m%d_%H%M%S\")}.png'\n",
    "                    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "                    print(f\"Successfully saved unified feature importance chart to: {plot_filename}\")\n",
    "                    plt.show()\n",
    "\n",
    "                    # 6. Export SHAP data to Excel\n",
    "                    sorted_shap_feature_names = [name for name, _ in sorted_feature_importances]\n",
    "                    final_X_data_for_plot_sorted = final_X_data_for_plot[sorted_shap_feature_names]\n",
    "                    shap_values_df_original_order = pd.DataFrame(final_shap_values_for_plot, columns=feature_names_list)\n",
    "                    shap_values_df_sorted = shap_values_df_original_order[sorted_shap_feature_names]\n",
    "                    shap_values_df_sorted.columns = [f'SHAP_{col}' for col in shap_values_df_sorted.columns]\n",
    "                    combined_shap_data_df = pd.concat([final_X_data_for_plot_sorted.reset_index(drop=True), shap_values_df_sorted.reset_index(drop=True)], axis=1)\n",
    "                    combined_shap_data_df['SHAP_Base_Value'] = final_base_value\n",
    "                    excel_filename_shap_data = f'shap_swarm_data_2level_weighted_{time.strftime(\"%Y%m%d_%H%M%S\")}.xlsx'\n",
    "                    combined_shap_data_df.to_excel(excel_filename_shap_data, index=False, engine='openpyxl')\n",
    "                    print(f\"Successfully exported aggregated SHAP swarm data to: {excel_filename_shap_data} (features sorted by unified importance)\")\n",
    "\n",
    "                    # 7. Plot and save SHAP swarm plot\n",
    "                    print(\"\\nPlotting SHAP swarm plot...\")\n",
    "                    shap_explanation = shap.Explanation(values=final_shap_values_for_plot, base_values=final_base_value, data=final_X_data_for_plot.values, feature_names=feature_names_list)\n",
    "                    plt.figure()\n",
    "                    shap.summary_plot(shap_explanation, final_X_data_for_plot, plot_type=\"dot\", max_display=N_FEATURES_TO_PLOT, show=False)\n",
    "                    plt.title(f'Two-Level R² Weighted SHAP Values (Aggregated over {valid_seeds_count} Seeds)')\n",
    "                    plt.tight_layout()\n",
    "                    shap_plot_filename = f'shap_summary_plot_2level_weighted_{time.strftime(\"%Y%m%d_%H%M%S\")}.png'\n",
    "                    plt.savefig(shap_plot_filename, dpi=300, bbox_inches='tight')\n",
    "                    print(f\"Successfully saved SHAP swarm plot to: {shap_plot_filename}\")\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print(\"Warning: Sum of all Level 2 weights (Stacking R²) is zero or invalid. Cannot perform final weighted average for feature importance.\")\n",
    "            else:\n",
    "                print(\"Warning: No valid weighted SHAP data was collected. Cannot perform unified analysis.\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nA critical error occurred during the [Two-Level Weighted] SHAP analysis: {e}\")\n",
    "            print(traceback.format_exc())\n",
    "\n",
    "    # =================================================================================\n",
    "    # --- End of Analysis Module ---\n",
    "    # =================================================================================\n",
    "\n",
    "else:\n",
    "    print(\"\\nError: No seeds completed successfully. Cannot calculate average results or generate plots.\")\n",
    "\n",
    "print(\"\\n--- Exporting detailed prediction results to Excel (pivoted by model) ---\")\n",
    "if all_plot_data_accumulated:\n",
    "    try:\n",
    "        plot_data_df_for_pivot = pd.DataFrame(all_plot_data_accumulated)\n",
    "        export_df_pivoted = pd.pivot_table(plot_data_df_for_pivot, \n",
    "                                           index=['Seed', 'Fold', 'Sample_Index', 'Actual'], \n",
    "                                           columns=['Model', 'Set'], \n",
    "                                           values='Predicted').reset_index()\n",
    "        export_df_pivoted.columns = ['_'.join(filter(None, map(str, col))).strip() for col in export_df_pivoted.columns.values]\n",
    "        excel_filename = f'cv_predictions_pivoted_{time.strftime(\"%Y%m%d_%H%M%S\")}.xlsx'\n",
    "        export_df_pivoted.to_excel(excel_filename, index=False, engine='openpyxl')\n",
    "        print(f\"Successfully exported pivoted prediction data to: {excel_filename}\")\n",
    "    except Exception as e: print(f\"!!! Error exporting pivoted prediction data: {e}\")\n",
    "\n",
    "print(\"\\n--- Exporting detailed R² and RMSE scores per seed/fold to Excel (pivoted by model) ---\")\n",
    "if all_scores_accumulated:\n",
    "    try:\n",
    "        scores_df = pd.DataFrame(all_scores_accumulated)\n",
    "        scores_df_pivoted = scores_df.pivot_table(index=['Seed', 'Fold'], columns=['Model', 'Metric'], values='Value').reset_index()\n",
    "        scores_df_pivoted.columns = [f'{col[1]}_{col[0]}' if col[1] else col[0] for col in scores_df_pivoted.columns]\n",
    "        excel_filename_scores = f'cv_model_scores_per_fold_pivoted_{time.strftime(\"%Y%m%d_%H%M%S\")}.xlsx'\n",
    "        scores_df_pivoted.to_excel(excel_filename_scores, index=False, engine='openpyxl')\n",
    "        print(f\"Successfully exported R² and RMSE scores per seed/fold to: {excel_filename_scores}\")\n",
    "    except Exception as e: print(f\"!!! Error exporting R² and RMSE scores per seed/fold: {e}\")\n",
    "\n",
    "print(\"\\n--- Script End ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80460624-fbbc-42e0-a063-1c998b4dee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script 5: Prediction\n",
    "# ==============================================================================\n",
    "# --- User Configuration ---\n",
    "# ==============================================================================\n",
    "# Please modify all tunable parameters in this section.\n",
    "\n",
    "# --- 1. Prediction File Settings ---\n",
    "# Excel file name for the unknown data to be predicted.\n",
    "UNKNOWN_DATA_FILE = 'Gap-prediction.xlsx' # For target1: Gap\n",
    "# UNKNOWN_DATA_FILE = 'Barrier-prediction.xlsx' # For target2: Barrier\n",
    "# Define the range to extract features (X_new) from the Excel file (using iloc slicing).\n",
    "# (slice(None), slice(1, None)) means reading all rows, and from the 2nd column (index 1) to the last column.\n",
    "# This will skip the first column (index 0) of the Excel file.\n",
    "UNKNOWN_DATA_FILE_COLUMN_RANGE = (slice(None), slice(1, None))\n",
    "\n",
    "# --- 2. Model Reuse and Training Settings ---\n",
    "# Whether to reuse the Stacking model already trained by a previous script.\n",
    "REUSE_PRETRAINED_STACKING_MODEL = True\n",
    "\n",
    "# The following parameters are only effective if REUSE_PRETRAINED_STACKING_MODEL = False (i.e., when retraining).\n",
    "PREDICT_CV_N_SPLITS = 10                  # Number of cross-validation folds for generating OOF predictions.\n",
    "PREDICT_META_LEARNER_N_SPLITS_CV = 10     # Number of 【splits】 for the Meta-Learner's internal cross-validation.\n",
    "PREDICT_META_LEARNER_N_REPEATS_CV = 3     # Number of 【repeats】 for the Meta-Learner's internal cross-validation.\n",
    "PREDICT_META_LEARNER_N_ITER_BAYESIAN = 50 # Number of iterations for Meta-Learner Bayesian Optimization.\n",
    "\n",
    "# --- 3. Base Learner Selection ---\n",
    "# !!! IMPORTANT: This list should be consistent with the configuration in the optimization and evaluation scripts !!!\n",
    "ENABLED_BASE_LEARNERS = [\n",
    "    'XGBR',   # XGBoost\n",
    "    'RF',     # Random Forest\n",
    "    'GBRT',   # Gradient Boosting Regressor\n",
    "    'HGBR',   # Hist Gradient Boosting\n",
    "    'ETR',    # Extra Trees Regressor\n",
    "    'CBR',    # CatBoost\n",
    "    'LGBM',   # LightGBM\n",
    "]\n",
    "\n",
    "# --- 4. Results Export Settings ---\n",
    "PREDICTION_OUTPUT_FILENAME_PREFIX = 'unknown_predictions'\n",
    "PREDICTION_EXPORT_TO_EXCEL = True\n",
    "PREDICTION_EXPORT_TO_CSV = False\n",
    "\n",
    "# --- 5. General Random State Settings ---\n",
    "# !!! IMPORTANT: This value should be consistent with DEFAULT_MODEL_RANDOM_STATE in the other two scripts !!!\n",
    "DEFAULT_MODEL_RANDOM_STATE = 0 # You can change this to any integer you prefer, e.g., 42 or 123\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- Main Script Body (Usually no modification is needed below) ---\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1. Library Imports and Environment Check ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import xgboost as XGB\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.base import clone\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "\n",
    "print(\"--- Starting Prediction on Unknown Data ---\")\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostRegressor\n",
    "    catboost_available = True\n",
    "except ImportError:\n",
    "    catboost_available = False\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "    lightgbm_available = True\n",
    "except ImportError:\n",
    "    lightgbm_available = False\n",
    "print(\"Library imports and environment check complete.\")\n",
    "\n",
    "\n",
    "# --- 2. Core Variable Loading and Preparation ---\n",
    "# The mock data fallback is removed; the script will now exit if X, Y, or grid_searches are not defined.\n",
    "# Assumes X, Y, and grid_searches are provided by upstream scripts (e.g., data prep and model optimization).\n",
    "if 'X' not in locals() and 'X' not in globals():\n",
    "    print(\"Error: Variable 'X' (training feature set) is not defined. Please ensure the data preparation and model optimization scripts have been run first.\")\n",
    "    sys.exit(1)\n",
    "if 'Y' not in locals() and 'Y' not in globals():\n",
    "    print(\"Error: Variable 'Y' (training target set) is not defined. Please ensure the data preparation and model optimization scripts have been run first.\")\n",
    "    sys.exit(1)\n",
    "if 'grid_searches' not in locals() and 'grid_searches' not in globals():\n",
    "    print(\"Error: Variable 'grid_searches' is not defined. Please ensure the model optimization script has been run first.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# [Fix] Use a new variable name to store the filtered models to avoid overwriting the original grid_searches.\n",
    "filtered_grid_searches = {name: gs for name, gs in grid_searches.items() if name in ENABLED_BASE_LEARNERS}\n",
    "print(f\"\\nModel filtering complete: Selected {len(filtered_grid_searches)} enabled models from {len(grid_searches)} available models: {list(filtered_grid_searches.keys())}\")\n",
    "if not filtered_grid_searches:\n",
    "    print(\"\\n!!! Fatal Error: No base learners were selected. Please check the ENABLED_BASE_LEARNERS list in the configuration.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Clean the feature names of the training data X and save the list for alignment with prediction data.\n",
    "feature_names_list = list(X.columns)\n",
    "X.columns = [re.sub(r'\\[|\\]|<', '_', col) for col in feature_names_list]\n",
    "feature_names_list = list(X.columns) # Update the list to the cleaned names\n",
    "\n",
    "print(f\"\\nAttempting to load the unknown prediction set from '{UNKNOWN_DATA_FILE}'...\")\n",
    "if not os.path.exists(UNKNOWN_DATA_FILE):\n",
    "    print(f\"Error: Prediction set file '{UNKNOWN_DATA_FILE}' not found. Please check the file path.\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    try:\n",
    "        full_data_from_excel = pd.read_excel(UNKNOWN_DATA_FILE)\n",
    "        # Slice the data according to the specified column range\n",
    "        X_new = full_data_from_excel.iloc[UNKNOWN_DATA_FILE_COLUMN_RANGE].copy()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Failed to load or process the prediction set '{UNKNOWN_DATA_FILE}': {e}. Please check the file content and column range settings.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "original_X_new_index = X_new.index # Save original index for results export\n",
    "\n",
    "# --- Modification: Align column names by position directly, instead of reindexing by name. ---\n",
    "# Check if the number of features in the sliced prediction set matches the training set.\n",
    "if X_new.shape[1] != len(feature_names_list):\n",
    "    print(f\"Error: The sliced prediction set X_new has {X_new.shape[1]} columns, but the training set has {len(feature_names_list)} features. The number of features does not match.\")\n",
    "    print(\"Please check the 'UNKNOWN_DATA_FILE_COLUMN_RANGE' setting to ensure it reads the correct number of features.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Directly assign the cleaned feature names from the training set to X_new's columns.\n",
    "# This assumes that the order of features in X_new is identical to the order in the training data X.\n",
    "# This avoids NaN issues caused by minor differences in column names.\n",
    "X_new.columns = feature_names_list\n",
    "\n",
    "# Check for NaNs that might have existed in the original X_new data.\n",
    "if X_new.isnull().any().any():\n",
    "    missing_cols_in_raw_X_new = X_new.columns[X_new.isnull().any()].tolist()\n",
    "    print(f\"Warning: The raw prediction set X_new contains missing values (NaN). Columns with missing values: {missing_cols_in_raw_X_new}\")\n",
    "    # X_new = X_new.fillna(0) # Optional filling strategy; uncomment if you need to fill NaNs.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "print(f\"\\nTraining data X shape: {X.shape}\")\n",
    "print(f\"Prediction data X_new shape (after assigning training column names): {X_new.shape}\")\n",
    "\n",
    "\n",
    "# --- 3. Core Functions and Model Training ---\n",
    "def initialize_best_estimators(grid_searches_dict):\n",
    "    \"\"\"Initializes base learner instances with the best found parameters.\"\"\"\n",
    "    estimators_init = {}\n",
    "    available_models = {\n",
    "        'XGBR': (XGB.XGBRegressor, {'objective': 'reg:squarederror', 'random_state': DEFAULT_MODEL_RANDOM_STATE}),\n",
    "        'RF': (RandomForestRegressor, {'random_state': DEFAULT_MODEL_RANDOM_STATE}),\n",
    "        'GBRT': (GradientBoostingRegressor, {'random_state': DEFAULT_MODEL_RANDOM_STATE}),\n",
    "        'ETR': (ExtraTreesRegressor, {'random_state': DEFAULT_MODEL_RANDOM_STATE}),\n",
    "        'HGBR': (HistGradientBoostingRegressor, {'random_state': DEFAULT_MODEL_RANDOM_STATE})\n",
    "    }\n",
    "    if catboost_available: available_models['CBR'] = (CatBoostRegressor, {'verbose': False, 'random_state': DEFAULT_MODEL_RANDOM_STATE, 'allow_writing_files': False})\n",
    "    if lightgbm_available: available_models['LGBM'] = (LGBMRegressor, {'random_state': DEFAULT_MODEL_RANDOM_STATE, 'verbosity': -1, 'objective': 'regression'})\n",
    "\n",
    "    print(\"Initializing base learners...\")\n",
    "    for name in grid_searches_dict.keys():\n",
    "        if name not in available_models:\n",
    "            print(f\"  Warning: Model {name} is not in the list of available models. Skipping initialization.\")\n",
    "            continue\n",
    "        model_class, fixed_params = available_models[name]\n",
    "        if name in grid_searches_dict and grid_searches_dict[name] is not None and hasattr(grid_searches_dict[name], 'best_estimator_'):\n",
    "            try:\n",
    "                estimators_init[name] = grid_searches_dict[name].best_estimator_\n",
    "                print(f\"  Successfully initialized {name} with optimized parameters.\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error initializing {name} from best_estimator_: {e}. This model will be skipped.\")\n",
    "        else:\n",
    "            print(f\"  Warning: Optimized results for {name} not found. Initializing with default parameters.\")\n",
    "            try:\n",
    "                estimators_init[name] = model_class(**fixed_params)\n",
    "                print(f\"  Successfully initialized {name} with default parameters.\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error initializing {name} with default parameters: {e}. This model will be skipped.\")\n",
    "    initialized_estimators = {k: v for k, v in estimators_init.items() if v}\n",
    "    if not initialized_estimators: print(\"Warning: No models were successfully initialized!\")\n",
    "    return initialized_estimators\n",
    "\n",
    "meta_learner_params = {\n",
    "    'elasticnet__alpha': Real(1e-5, 10.0, prior='log-uniform', name='elasticnet__alpha'),\n",
    "    'elasticnet__l1_ratio': Real(0.0, 1.0, prior='uniform', name='elasticnet__l1_ratio')\n",
    "}\n",
    "final_meta_learner = None; base_estimators_for_final_training = None\n",
    "\n",
    "if REUSE_PRETRAINED_STACKING_MODEL:\n",
    "    print(\"\\n--- Attempting to reuse the previously trained Stacking model ---\")\n",
    "    if 'global_best_meta_learner' in locals() and global_best_meta_learner is not None and hasattr(global_best_meta_learner, 'predict'):\n",
    "        final_meta_learner = global_best_meta_learner\n",
    "        print(\"Successfully reused the previously trained meta-learner.\")\n",
    "    else:\n",
    "        print(\"Warning: No valid 'global_best_meta_learner' found. Falling back to retraining mode.\")\n",
    "        REUSE_PRETRAINED_STACKING_MODEL = False\n",
    "\n",
    "if not REUSE_PRETRAINED_STACKING_MODEL:\n",
    "    print(\"\\n--- Retraining the final Stacked model ---\")\n",
    "    base_estimators_for_oof = initialize_best_estimators(filtered_grid_searches)\n",
    "    if not base_estimators_for_oof:\n",
    "        print(\"Error: No base learners available to train the Stacked model.\"); sys.exit(1)\n",
    "\n",
    "    model_names_available = list(base_estimators_for_oof.keys())\n",
    "    oof_preds_for_meta_training = np.zeros((len(X), len(model_names_available)))\n",
    "    \n",
    "    kf_for_oof = KFold(n_splits=PREDICT_CV_N_SPLITS, shuffle=True, random_state=DEFAULT_MODEL_RANDOM_STATE)\n",
    "\n",
    "    print(f\"Starting {PREDICT_CV_N_SPLITS}-fold cross-validation to generate OOF predictions (Random Seed: {DEFAULT_MODEL_RANDOM_STATE})...\")\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf_for_oof.split(X, Y)):\n",
    "        print(f\"  Fold {fold_idx+1}/{PREDICT_CV_N_SPLITS}\")\n",
    "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        Y_train_fold = Y.iloc[train_idx]\n",
    "        for i, (name, estimator_template) in enumerate(base_estimators_for_oof.items()):\n",
    "            estimator_fold = clone(estimator_template)\n",
    "            try:\n",
    "                estimator_fold.fit(X_train_fold, Y_train_fold)\n",
    "                oof_preds_for_meta_training[val_idx, i] = estimator_fold.predict(X_val_fold)\n",
    "            except Exception as e:\n",
    "                print(f\"    Warning: Model {name} failed during fit/predict: {e}. OOF predictions will be zero.\")\n",
    "\n",
    "    if np.all(oof_preds_for_meta_training == 0) or np.any(np.isnan(oof_preds_for_meta_training)):\n",
    "        print(\"Error: OOF predictions are invalid. Cannot train meta-learner. Please check if base learners are training correctly.\"); sys.exit(1)\n",
    "\n",
    "    print(\"Starting Bayesian Optimization and training for the meta-learner...\")\n",
    "    meta_bayes_search = BayesSearchCV(\n",
    "        estimator=Pipeline([('scaler', StandardScaler()), ('elasticnet', ElasticNet(random_state=DEFAULT_MODEL_RANDOM_STATE, max_iter=2000))]),\n",
    "        search_spaces=meta_learner_params, n_iter=PREDICT_META_LEARNER_N_ITER_BAYESIAN, scoring='r2',\n",
    "        cv=RepeatedKFold(n_splits=PREDICT_META_LEARNER_N_SPLITS_CV, n_repeats=PREDICT_META_LEARNER_N_REPEATS_CV, random_state=DEFAULT_MODEL_RANDOM_STATE),\n",
    "        n_jobs=-1, random_state=DEFAULT_MODEL_RANDOM_STATE, verbose=1)\n",
    "    try:\n",
    "        meta_bayes_search.fit(oof_preds_for_meta_training, Y)\n",
    "        final_meta_learner = meta_bayes_search.best_estimator_\n",
    "        print(\"\\n--- Meta-learner training complete ---\")\n",
    "        print(f\"Meta-Learner Best Score (CV R² on Full OOF): {meta_bayes_search.best_score_:.4f}\")\n",
    "        print(f\"Meta-Learner Best Parameters: {dict(meta_bayes_search.best_params_)}\")\n",
    "\n",
    "        if final_meta_learner and 'elasticnet' in final_meta_learner.named_steps:\n",
    "            elastic_net_model = final_meta_learner.named_steps['elasticnet']\n",
    "            if hasattr(elastic_net_model, 'coef_'):\n",
    "                print(\"\\n--- Base Learner Coefficients in Meta-Learner (ElasticNet) ---\")\n",
    "                for i, name in enumerate(model_names_available):\n",
    "                    if i < len(elastic_net_model.coef_):\n",
    "                        print(f\"  {name}: {elastic_net_model.coef_[i]:.6f}\")\n",
    "                    else:\n",
    "                        print(f\"  Warning: Coefficient for model {name} not found (index out of bounds).\")\n",
    "            else:\n",
    "                print(\"Warning: Meta-learner (ElasticNet) has no 'coef_' attribute. Cannot display coefficients.\")\n",
    "        else:\n",
    "            print(\"Warning: Meta-learner or its ElasticNet component not found. Cannot display coefficients.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n!!! Meta-learner training failed: {e}. Cannot proceed with prediction.\"); sys.exit(1)\n",
    "\n",
    "print(\"\\n--- Training final base learners on the entire training dataset ---\")\n",
    "base_estimators_for_final_training = initialize_best_estimators(filtered_grid_searches)\n",
    "for name, estimator in base_estimators_for_final_training.items():\n",
    "    print(f\"  Training the final {name} model...\")\n",
    "    try:\n",
    "        estimator.fit(X, Y)\n",
    "    except Exception as e:\n",
    "        print(f\"    Warning: Failed to train the final {name} model: {e}. This model will be removed from the prediction process.\")\n",
    "        base_estimators_for_final_training[name] = None\n",
    "base_estimators_for_final_training = {k: v for k, v in base_estimators_for_final_training.items() if v}\n",
    "\n",
    "\n",
    "# --- 4. Predicting on Unknown Data ---\n",
    "if not final_meta_learner or not base_estimators_for_final_training:\n",
    "    print(\"Fatal Error: The Stacked model could not be built successfully. Cannot make predictions.\"); sys.exit(1)\n",
    "\n",
    "print(\"\\n--- Making Stacked predictions on the unknown data ---\")\n",
    "base_predictions_on_new_data, base_model_names_for_prediction = [], []\n",
    "print(\"Generating predictions from base learners on the new data...\")\n",
    "for name, estimator in base_estimators_for_final_training.items():\n",
    "    try:\n",
    "        pred = estimator.predict(X_new)\n",
    "        base_predictions_on_new_data.append(pred)\n",
    "        base_model_names_for_prediction.append(name)\n",
    "        print(f\"  {name} prediction complete.\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error while predicting with model {name} on new data: {e}. This model will be skipped.\")\n",
    "\n",
    "if not base_predictions_on_new_data:\n",
    "    print(\"Error: All base learners failed to predict on the new data.\"); sys.exit(1)\n",
    "\n",
    "meta_features_for_prediction = np.column_stack(base_predictions_on_new_data)\n",
    "print(f\"Shape of base learner predictions (input for meta-learner): {meta_features_for_prediction.shape}\")\n",
    "\n",
    "print(\"Making final Stacked prediction using the meta-learner...\")\n",
    "try:\n",
    "    final_stacked_predictions = final_meta_learner.predict(meta_features_for_prediction)\n",
    "    print(\"Final Stacked prediction complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during final prediction by meta-learner: {e}\"); sys.exit(1)\n",
    "\n",
    "\n",
    "# --- 5. Organizing and Exporting Prediction Results ---\n",
    "print(\"\\n--- Organizing and exporting prediction results ---\")\n",
    "results_df = pd.DataFrame(index=original_X_new_index) # Use the original index\n",
    "for i, name in enumerate(base_model_names_for_prediction):\n",
    "    results_df[f'{name}_Prediction'] = base_predictions_on_new_data[i]\n",
    "results_df['Stacked_Prediction'] = final_stacked_predictions\n",
    "\n",
    "current_timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_filename_base = f\"{PREDICTION_OUTPUT_FILENAME_PREFIX}_{current_timestamp}\"\n",
    "\n",
    "if PREDICTION_EXPORT_TO_EXCEL:\n",
    "    excel_filename = f\"{output_filename_base}.xlsx\"\n",
    "    try:\n",
    "        results_df.to_excel(excel_filename, index=True, engine='openpyxl')\n",
    "        print(f\"Prediction results successfully exported to Excel: {excel_filename}\")\n",
    "    except ImportError:\n",
    "        print(\"!!! Exporting to Excel requires the 'openpyxl' library. Switching to CSV export.\")\n",
    "        PREDICTION_EXPORT_TO_EXCEL = False\n",
    "    except Exception as e:\n",
    "        print(f\"!!! Error exporting prediction results to Excel: {e}\")\n",
    "        PREDICTION_EXPORT_TO_EXCEL = False\n",
    "\n",
    "if PREDICTION_EXPORT_TO_CSV or not PREDICTION_EXPORT_TO_EXCEL:\n",
    "    csv_filename = f\"{output_filename_base}.csv\"\n",
    "    try:\n",
    "        results_df.to_csv(csv_filename, index=True)\n",
    "        print(f\"Prediction results successfully exported to CSV: {csv_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"!!! Error exporting prediction results to CSV: {e}\")\n",
    "\n",
    "print(\"\\nPrediction script for unknown data has finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (matsci-ai)",
   "language": "python",
   "name": "matsci-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
